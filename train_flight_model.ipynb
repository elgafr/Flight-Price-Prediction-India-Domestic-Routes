{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41c2526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Fungsi untuk evaluasi model\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"\\n{model_name} - Metrics\")\n",
    "    print(f\"MSE: {mse:.2f}\")\n",
    "    print(f\"MAE: {mae:.2f}\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(f\"R² Score: {r2:.4f}\")\n",
    "    return mse, mae, rmse, r2\n",
    "\n",
    "# Fungsi untuk menghitung confidence scores\n",
    "def get_confidence_scores(model, X_test, model_type):\n",
    "    if model_type == \"DecisionTree\":\n",
    "        n_bootstraps = 100\n",
    "        predictions = []\n",
    "        for _ in range(n_bootstraps):\n",
    "            idx = np.random.choice(X_test.shape[0], size=X_test.shape[0], replace=True)\n",
    "            X_boot = X_test[idx]\n",
    "            predictions.append(model.predict(X_boot))\n",
    "        predictions = np.array(predictions)\n",
    "        mean_pred = predictions.mean(axis=0)\n",
    "        std_pred = predictions.std(axis=0)\n",
    "        confidence_scores = 1 / (1 + std_pred / (mean_pred + 1e-10))\n",
    "    elif model_type == \"RandomForest\":\n",
    "        tree_predictions = np.array([tree.predict(X_test) for tree in model.estimators_])\n",
    "        mean_pred = tree_predictions.mean(axis=0)\n",
    "        std_pred = tree_predictions.std(axis=0)\n",
    "        confidence_scores = 1 / (1 + std_pred / (mean_pred + 1e-10))\n",
    "    elif model_type == \"XGBoost\":\n",
    "        n_samples = 100\n",
    "        predictions = []\n",
    "        for _ in range(n_samples):\n",
    "            noise = np.random.normal(0, 0.01, X_test.shape)\n",
    "            X_noisy = X_test + noise\n",
    "            predictions.append(model.predict(X_noisy))\n",
    "        predictions = np.array(predictions)\n",
    "        mean_pred = predictions.mean(axis=0)\n",
    "        std_pred = predictions.std(axis=0)\n",
    "        confidence_scores = 1 / (1 + std_pred / (mean_pred + 1e-10))\n",
    "    return confidence_scores\n",
    "\n",
    "# Buat folder models jika belum ada\n",
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models')\n",
    "\n",
    "# 1. Muat dataset\n",
    "data = pd.read_csv('Flight Price Prediction Dataset.csv')\n",
    "\n",
    "# 2. Preprocessing\n",
    "if 'Unnamed: 0' in data.columns:\n",
    "    data = data.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "if data.isnull().sum().sum() > 0:\n",
    "    print(\"Data memiliki nilai null, mengisi dengan modus untuk kategorikal dan rata-rata untuk numerik...\")\n",
    "    for col in data.columns:\n",
    "        if data[col].dtype == 'object':\n",
    "            data[col] = data[col].fillna(data[col].mode()[0])\n",
    "        else:\n",
    "            data[col] = data[col].fillna(data[col].mean())\n",
    "\n",
    "X = data.drop(columns=['price'])\n",
    "y = data['price']\n",
    "\n",
    "# Simpan nilai unik untuk dropdown dashboard\n",
    "unique_values = {}\n",
    "categorical_columns = ['airline', 'flight', 'source_city', 'departure_time', 'stops', \n",
    "                      'arrival_time', 'destination_city', 'class']\n",
    "for col in categorical_columns:\n",
    "    unique_values[col] = list(X[col].unique())\n",
    "joblib.dump(unique_values, 'models/unique_values.joblib')\n",
    "\n",
    "airline_flight_map = X.groupby('airline')['flight'].unique().to_dict()\n",
    "joblib.dump(airline_flight_map, 'models/airline_flight_map.joblib')\n",
    "\n",
    "numeric_columns = ['duration', 'days_left']\n",
    "\n",
    "# Buat preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_columns),\n",
    "        ('num', StandardScaler(), numeric_columns)\n",
    "    ])\n",
    "\n",
    "joblib.dump(preprocessor, 'models/preprocessor.joblib')\n",
    "\n",
    "# Pisahkan data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "joblib.dump((X_train, X_test, y_train, y_test), 'models/processed_data.joblib')\n",
    "\n",
    "# Simpan scaler untuk numerik\n",
    "scaler = preprocessor.named_transformers_['num']\n",
    "joblib.dump(scaler, 'models/scaler.joblib')\n",
    "\n",
    "# 3. Inisialisasi hasil dan model\n",
    "results = []\n",
    "model_dict = {}\n",
    "confidence_scores = {}\n",
    "\n",
    "# 4. Pelatihan model tanpa feature selection\n",
    "print(\"\\n=== Non-Feature Selection ===\")\n",
    "\n",
    "# Decision Tree\n",
    "dt_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', DecisionTreeRegressor(random_state=42))\n",
    "])\n",
    "dt_pipeline.fit(X_train, y_train)\n",
    "y_pred_dt = dt_pipeline.predict(X_test)\n",
    "mse_dt, mae_dt, rmse_dt, r2_dt = evaluate_model(y_test, y_pred_dt, \"Decision Tree\")\n",
    "results.append({\"Model\": \"Decision Tree\", \"Feature Selection\": \"None\", \"MSE\": mse_dt, \"MAE\": mae_dt, \"RMSE\": rmse_dt, \"R²\": r2_dt})\n",
    "model_dict[\"DecisionTree_None\"] = dt_pipeline\n",
    "confidence_scores[\"DecisionTree_None\"] = get_confidence_scores(dt_pipeline.named_steps['model'], preprocessor.transform(X_test), \"DecisionTree\")\n",
    "joblib.dump(dt_pipeline, 'models/DecisionTree_None.joblib')\n",
    "pd.DataFrame({'confidence': confidence_scores[\"DecisionTree_None\"]}).to_csv('models/DecisionTree_None_confidence.csv', index=False)\n",
    "\n",
    "# Random Forest\n",
    "rf_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "y_pred_rf = rf_pipeline.predict(X_test)\n",
    "mse_rf, mae_rf, rmse_rf, r2_rf = evaluate_model(y_test, y_pred_rf, \"Random Forest\")\n",
    "results.append({\"Model\": \"Random Forest\", \"Feature Selection\": \"None\", \"MSE\": mse_rf, \"MAE\": mae_rf, \"RMSE\": rmse_rf, \"R²\": r2_rf})\n",
    "model_dict[\"RandomForest_None\"] = rf_pipeline\n",
    "confidence_scores[\"RandomForest_None\"] = get_confidence_scores(rf_pipeline.named_steps['model'], preprocessor.transform(X_test), \"RandomForest\")\n",
    "joblib.dump(rf_pipeline, 'models/RandomForest_None.joblib')\n",
    "pd.DataFrame({'confidence': confidence_scores[\"RandomForest_None\"]}).to_csv('models/RandomForest_None_confidence.csv', index=False)\n",
    "\n",
    "# XGBoost\n",
    "xgb_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', XGBRegressor(random_state=42, objective='reg:squarederror'))\n",
    "])\n",
    "xgb_pipeline.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_pipeline.predict(X_test)\n",
    "mse_xgb, mae_xgb, rmse_xgb, r2_xgb = evaluate_model(y_test, y_pred_xgb, \"XGBoost\")\n",
    "results.append({\"Model\": \"XGBoost\", \"Feature Selection\": \"None\", \"MSE\": mse_xgb, \"MAE\": mae_xgb, \"RMSE\": rmse_xgb, \"R²\": r2_xgb})\n",
    "model_dict[\"XGBoost_None\"] = xgb_pipeline\n",
    "confidence_scores[\"XGBoost_None\"] = get_confidence_scores(xgb_pipeline.named_steps['model'], preprocessor.transform(X_test), \"XGBoost\")\n",
    "joblib.dump(xgb_pipeline, 'models/XGBoost_None.joblib')\n",
    "pd.DataFrame({'confidence': confidence_scores[\"XGBoost_None\"]}).to_csv('models/XGBoost_None_confidence.csv', index=False)\n",
    "\n",
    "# 5. Feature Selection: Mutual Information\n",
    "print(\"\\n=== Feature Selection: Mutual Information ===\")\n",
    "# Buat pipeline dengan feature selection\n",
    "mi_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', SelectKBest(score_func=mutual_info_regression, k=5))\n",
    "])\n",
    "\n",
    "# Fit pipeline untuk mendapatkan fitur terpilih\n",
    "mi_pipeline.fit(X_train, y_train)\n",
    "selected_features_idx = mi_pipeline.named_steps['selector'].get_support()\n",
    "# Dapatkan nama fitur setelah preprocessing\n",
    "feature_names = (mi_pipeline.named_steps['preprocessor']\n",
    "                 .named_transformers_['cat']\n",
    "                 .get_feature_names_out(categorical_columns)\n",
    "                 .tolist() + numeric_columns)\n",
    "selected_features_mi = [feature_names[i] for i, selected in enumerate(selected_features_idx) if selected]\n",
    "print(\"Selected features (MI):\", selected_features_mi)\n",
    "joblib.dump(mi_pipeline.named_steps['selector'], 'models/selector_mi.joblib')\n",
    "joblib.dump(selected_features_mi, 'models/selected_features_mi.joblib')\n",
    "\n",
    "# Decision Tree (MI)\n",
    "dt_mi_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', SelectKBest(score_func=mutual_info_regression, k=5)),\n",
    "    ('model', DecisionTreeRegressor(random_state=42))\n",
    "])\n",
    "dt_mi_pipeline.fit(X_train, y_train)\n",
    "y_pred_dt_mi = dt_mi_pipeline.predict(X_test)\n",
    "mse_dt_mi, mae_dt_mi, rmse_dt_mi, r2_dt_mi = evaluate_model(y_test, y_pred_dt_mi, \"Decision Tree (MI)\")\n",
    "results.append({\"Model\": \"Decision Tree\", \"Feature Selection\": \"MI\", \"MSE\": mse_dt_mi, \"MAE\": mae_dt_mi, \"RMSE\": rmse_dt_mi, \"R²\": r2_dt_mi})\n",
    "model_dict[\"DecisionTree_MI\"] = dt_mi_pipeline\n",
    "confidence_scores[\"DecisionTree_MI\"] = get_confidence_scores(dt_mi_pipeline.named_steps['model'], \n",
    "                                                            dt_mi_pipeline.named_steps['selector'].transform(preprocessor.transform(X_test)), \n",
    "                                                            \"DecisionTree\")\n",
    "joblib.dump(dt_mi_pipeline, 'models/DecisionTree_MI.joblib')\n",
    "pd.DataFrame({'confidence': confidence_scores[\"DecisionTree_MI\"]}).to_csv('models/DecisionTree_MI_confidence.csv', index=False)\n",
    "\n",
    "# Random Forest (MI)\n",
    "rf_mi_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', SelectKBest(score_func=mutual_info_regression, k=5)),\n",
    "    ('model', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "rf_mi_pipeline.fit(X_train, y_train)\n",
    "y_pred_rf_mi = rf_mi_pipeline.predict(X_test)\n",
    "mse_rf_mi, mae_rf_mi, rmse_rf_mi, r2_rf_mi = evaluate_model(y_test, y_pred_rf_mi, \"Random Forest (MI)\")\n",
    "results.append({\"Model\": \"Random Forest\", \"Feature Selection\": \"MI\", \"MSE\": mse_rf_mi, \"MAE\": mae_rf_mi, \"RMSE\": rmse_rf_mi, \"R²\": r2_rf_mi})\n",
    "model_dict[\"RandomForest_MI\"] = rf_mi_pipeline\n",
    "confidence_scores[\"RandomForest_MI\"] = get_confidence_scores(rf_mi_pipeline.named_steps['model'], \n",
    "                                                            rf_mi_pipeline.named_steps['selector'].transform(preprocessor.transform(X_test)), \n",
    "                                                            \"RandomForest\")\n",
    "joblib.dump(rf_mi_pipeline, 'models/RandomForest_MI.joblib')\n",
    "pd.DataFrame({'confidence': confidence_scores[\"RandomForest_MI\"]}).to_csv('models/RandomForest_MI_confidence.csv', index=False)\n",
    "\n",
    "# XGBoost (MI)\n",
    "xgb_mi_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', SelectKBest(score_func=mutual_info_regression, k=5)),\n",
    "    ('model', XGBRegressor(random_state=42, objective='reg:squarederror'))\n",
    "])\n",
    "xgb_mi_pipeline.fit(X_train, y_train)\n",
    "y_pred_xgb_mi = xgb_mi_pipeline.predict(X_test)\n",
    "mse_xgb_mi, mae_xgb_mi, rmse_xgb_mi, r2_xgb_mi = evaluate_model(y_test, y_pred_xgb_mi, \"XGBoost (MI)\")\n",
    "results.append({\"Model\": \"XGBoost\", \"Feature Selection\": \"MI\", \"MSE\": mse_xgb_mi, \"MAE\": mae_xgb_mi, \"RMSE\": rmse_xgb_mi, \"R²\": r2_xgb_mi})\n",
    "model_dict[\"XGBoost_MI\"] = xgb_mi_pipeline\n",
    "confidence_scores[\"XGBoost_MI\"] = get_confidence_scores(xgb_mi_pipeline.named_steps['model'], \n",
    "                                                        xgb_mi_pipeline.named_steps['selector'].transform(preprocessor.transform(X_test)), \n",
    "                                                        \"XGBoost\")\n",
    "joblib.dump(xgb_mi_pipeline, 'models/XGBoost_MI.joblib')\n",
    "pd.DataFrame({'confidence': confidence_scores[\"XGBoost_MI\"]}).to_csv('models/XGBoost_MI_confidence.csv', index=False)\n",
    "\n",
    "# 6. Feature Selection: Sequential Forward Selection (SFS)\n",
    "print(\"\\n=== Feature Selection: SFS ===\")\n",
    "# SFS tidak bisa langsung digunakan dalam pipeline karena membutuhkan data yang sudah di-preprocess\n",
    "# Preprocess data terlebih dahulu\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n",
    "feature_names = (preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_columns).tolist() + numeric_columns)\n",
    "\n",
    "# Jalankan SFS\n",
    "sfs = SFS(RandomForestRegressor(n_estimators=10, random_state=42), \n",
    "          k_features=5, forward=True, scoring='r2', cv=5, n_jobs=-1)\n",
    "sfs.fit(X_train_preprocessed, y_train)\n",
    "selected_features_idx = list(sfs.k_feature_idx_)\n",
    "selected_features_sfs = [feature_names[i] for i in selected_features_idx]\n",
    "print(\"Selected features (SFS):\", selected_features_sfs)\n",
    "joblib.dump(sfs, 'models/sfs.joblib')\n",
    "joblib.dump(selected_features_sfs, 'models/selected_features_sfs.joblib')\n",
    "\n",
    "# Buat pipeline dengan SFS (menggunakan selector manual)\n",
    "class SFSSelector:\n",
    "    def __init__(self, selected_indices):\n",
    "        self.selected_indices = selected_indices\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[:, self.selected_indices]\n",
    "\n",
    "# Decision Tree (SFS)\n",
    "dt_sfs_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', SFSSelector(selected_features_idx)),\n",
    "    ('model', DecisionTreeRegressor(random_state=42))\n",
    "])\n",
    "dt_sfs_pipeline.fit(X_train, y_train)\n",
    "y_pred_dt_sfs = dt_sfs_pipeline.predict(X_test)\n",
    "mse_dt_sfs, mae_dt_sfs, rmse_dt_sfs, r2_dt_sfs = evaluate_model(y_test, y_pred_dt_sfs, \"Decision Tree (SFS)\")\n",
    "results.append({\"Model\": \"Decision Tree\", \"Feature Selection\": \"SFS\", \"MSE\": mse_dt_sfs, \"MAE\": mae_dt_sfs, \"RMSE\": rmse_dt_sfs, \"R²\": r2_dt_sfs})\n",
    "model_dict[\"DecisionTree_SFS\"] = dt_sfs_pipeline\n",
    "confidence_scores[\"DecisionTree_SFS\"] = get_confidence_scores(dt_sfs_pipeline.named_steps['model'], \n",
    "                                                             dt_sfs_pipeline.named_steps['selector'].transform(preprocessor.transform(X_test)), \n",
    "                                                             \"DecisionTree\")\n",
    "joblib.dump(dt_sfs_pipeline, 'models/DecisionTree_SFS.joblib')\n",
    "pd.DataFrame({'confidence': confidence_scores[\"DecisionTree_SFS\"]}).to_csv('models/DecisionTree_SFS_confidence.csv', index=False)\n",
    "\n",
    "# Random Forest (SFS)\n",
    "rf_sfs_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', SFSSelector(selected_features_idx)),\n",
    "    ('model', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "rf_sfs_pipeline.fit(X_train, y_train)\n",
    "y_pred_rf_sfs = rf_sfs_pipeline.predict(X_test)\n",
    "mse_rf_sfs, mae_rf_sfs, rmse_rf_sfs, r2_rf_sfs = evaluate_model(y_test, y_pred_rf_sfs, \"Random Forest (SFS)\")\n",
    "results.append({\"Model\": \"Random Forest\", \"Feature Selection\": \"SFS\", \"MSE\": mse_rf_sfs, \"MAE\": mae_rf_sfs, \"RMSE\": rmse_rf_sfs, \"R²\": r2_rf_sfs})\n",
    "model_dict[\"RandomForest_SFS\"] = rf_sfs_pipeline\n",
    "confidence_scores[\"RandomForest_SFS\"] = get_confidence_scores(rf_sfs_pipeline.named_steps['model'], \n",
    "                                                             rf_sfs_pipeline.named_steps['selector'].transform(preprocessor.transform(X_test)), \n",
    "                                                             \"RandomForest\")\n",
    "joblib.dump(rf_sfs_pipeline, 'models/RandomForest_SFS.joblib')\n",
    "pd.DataFrame({'confidence': confidence_scores[\"RandomForest_SFS\"]}).to_csv('models/RandomForest_SFS_confidence.csv', index=False)\n",
    "\n",
    "# XGBoost (SFS)\n",
    "xgb_sfs_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', SFSSelector(selected_features_idx)),\n",
    "    ('model', XGBRegressor(random_state=42, objective='reg:squarederror'))\n",
    "])\n",
    "xgb_sfs_pipeline.fit(X_train, y_train)\n",
    "y_pred_xgb_sfs = xgb_sfs_pipeline.predict(X_test)\n",
    "mse_xgb_sfs, mae_xgb_sfs, rmse_xgb_sfs, r2_xgb_sfs = evaluate_model(y_test, y_pred_xgb_sfs, \"XGBoost (SFS)\")\n",
    "results.append({\"Model\": \"XGBoost\", \"Feature Selection\": \"SFS\", \"MSE\": mse_xgb_sfs, \"MAE\": mae_xgb_sfs, \"RMSE\": rmse_xgb_sfs, \"R²\": r2_xgb_sfs})\n",
    "model_dict[\"XGBoost_SFS\"] = xgb_sfs_pipeline\n",
    "confidence_scores[\"XGBoost_SFS\"] = get_confidence_scores(xgb_sfs_pipeline.named_steps['model'], \n",
    "                                                        xgb_sfs_pipeline.named_steps['selector'].transform(preprocessor.transform(X_test)), \n",
    "                                                        \"XGBoost\")\n",
    "joblib.dump(xgb_sfs_pipeline, 'models/XGBoost_SFS.joblib')\n",
    "pd.DataFrame({'confidence': confidence_scores[\"XGBoost_SFS\"]}).to_csv('models/XGBoost_SFS_confidence.csv', index=False)\n",
    "\n",
    "# 7. Simpan hasil evaluasi\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('models/model_results.csv', index=False)\n",
    "print(\"\\nHasil evaluasi disimpan ke 'models/model_results.csv'\")\n",
    "\n",
    "# Cetak perbandingan\n",
    "print(\"\\n=== Comparison Table ===\")\n",
    "print(\"\\nNon-Feature Selection:\")\n",
    "print(results_df[results_df['Feature Selection'] == 'None'][['Model', 'MSE', 'MAE', 'RMSE', 'R²']])\n",
    "print(\"\\nMutual Information:\")\n",
    "print(results_df[results_df['Feature Selection'] == 'MI'][['Model', 'MSE', 'MAE', 'RMSE', 'R²']])\n",
    "print(\"\\nSFS:\")\n",
    "print(results_df[results_df['Feature Selection'] == 'SFS'][['Model', 'MSE', 'MAE', 'RMSE', 'R²']])\n",
    "\n",
    "# Simpan confidence scores\n",
    "joblib.dump(confidence_scores, 'models/confidence_scores.joblib')\n",
    "print(\"Confidence scores disimpan ke 'models/confidence_scores.joblib'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2547d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Non-Feature Selection ===\n",
      "\n",
      "Decision Tree - Metrics\n",
      "MSE: 8865106.64\n",
      "MAE: 878.96\n",
      "RMSE: 2977.43\n",
      "R² Score: 0.9828\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Fungsi untuk evaluasi model\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"\\n{model_name} - Metrics\")\n",
    "    print(f\"MSE: {mse:.2f}\")\n",
    "    print(f\"MAE: {mae:.2f}\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(f\"R² Score: {r2:.4f}\")\n",
    "    return mse, mae, rmse, r2\n",
    "\n",
    "# Fungsi untuk menghitung confidence scores\n",
    "def get_confidence_scores(model, X_test, model_type):\n",
    "    if model_type == \"DecisionTree\":\n",
    "        n_bootstraps = 100\n",
    "        predictions = []\n",
    "        for _ in range(n_bootstraps):\n",
    "            idx = np.random.choice(X_test.shape[0], size=X_test.shape[0], replace=True)\n",
    "            X_boot = X_test[idx]\n",
    "            predictions.append(model.predict(X_boot))\n",
    "        predictions = np.array(predictions)\n",
    "        mean_pred = predictions.mean(axis=0)\n",
    "        std_pred = predictions.std(axis=0)\n",
    "        confidence_scores = 1 / (1 + std_pred / (mean_pred + 1e-10))\n",
    "    elif model_type == \"RandomForest\":\n",
    "        tree_predictions = np.array([tree.predict(X_test) for tree in model.estimators_])\n",
    "        mean_pred = tree_predictions.mean(axis=0)\n",
    "        std_pred = tree_predictions.std(axis=0)\n",
    "        confidence_scores = 1 / (1 + std_pred / (mean_pred + 1e-10))\n",
    "    elif model_type == \"XGBoost\":\n",
    "        n_samples = 100\n",
    "        predictions = []\n",
    "        for _ in range(n_samples):\n",
    "            noise = np.random.normal(0, 0.01, X_test.shape)\n",
    "            X_noisy = X_test + noise\n",
    "            predictions.append(model.predict(X_noisy))\n",
    "        predictions = np.array(predictions)\n",
    "        mean_pred = predictions.mean(axis=0)\n",
    "        std_pred = predictions.std(axis=0)\n",
    "        confidence_scores = 1 / (1 + std_pred / (mean_pred + 1e-10))\n",
    "    return confidence_scores\n",
    "\n",
    "# Buat folder models jika belum ada\n",
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models')\n",
    "\n",
    "# 1. Muat dataset\n",
    "data = pd.read_csv('Flight Price Prediction Dataset.csv')\n",
    "\n",
    "# 2. Preprocessing\n",
    "if 'Unnamed: 0' in data.columns:\n",
    "    data = data.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "if data.isnull().sum().sum() > 0:\n",
    "    print(\"Data memiliki nilai null, mengisi dengan modus untuk kategorikal dan rata-rata untuk numerik...\")\n",
    "    for col in data.columns:\n",
    "        if data[col].dtype == 'object':\n",
    "            data[col] = data[col].fillna(data[col].mode()[0])\n",
    "        else:\n",
    "            data[col] = data[col].fillna(data[col].mean())\n",
    "\n",
    "X = data.drop(columns=['price'])\n",
    "y = data['price']\n",
    "\n",
    "# Simpan nilai unik untuk dropdown dashboard\n",
    "unique_values = {}\n",
    "categorical_columns = ['airline', 'flight', 'source_city', 'departure_time', 'stops', \n",
    "                      'arrival_time', 'destination_city', 'class']\n",
    "for col in categorical_columns:\n",
    "    unique_values[col] = list(X[col].unique())\n",
    "joblib.dump(unique_values, 'models/unique_values.joblib')\n",
    "\n",
    "airline_flight_map = X.groupby('airline')['flight'].unique().to_dict()\n",
    "joblib.dump(airline_flight_map, 'models/airline_flight_map.joblib')\n",
    "\n",
    "numeric_columns = ['duration', 'days_left']\n",
    "\n",
    "# Buat preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_columns),\n",
    "        ('num', StandardScaler(), numeric_columns)\n",
    "    ])\n",
    "\n",
    "joblib.dump(preprocessor, 'models/preprocessor.joblib')\n",
    "\n",
    "# Pisahkan data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "joblib.dump((X_train, X_test, y_train, y_test), 'models/processed_data.joblib')\n",
    "\n",
    "# Simpan scaler untuk numerik\n",
    "# Simpan scaler untuk numerik\n",
    "preprocessor.fit(X_train)\n",
    "scaler = preprocessor.named_transformers_['num']  # Corrected line\n",
    "joblib.dump(scaler, 'models/scaler.joblib')\n",
    "\n",
    "\n",
    "# 3. Inisialisasi hasil dan model\n",
    "results = []\n",
    "model_dict = {}\n",
    "confidence_scores = {}\n",
    "\n",
    "# 4. Pelatihan model tanpa feature selection\n",
    "print(\"\\n=== Non-Feature Selection ===\")\n",
    "\n",
    "# Decision Tree\n",
    "dt_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', DecisionTreeRegressor(random_state=42))\n",
    "])\n",
    "dt_pipeline.fit(X_train, y_train)\n",
    "y_pred_dt = dt_pipeline.predict(X_test)\n",
    "mse_dt, mae_dt, rmse_dt, r2_dt = evaluate_model(y_test, y_pred_dt, \"Decision Tree\")\n",
    "results.append({\"Model\": \"Decision Tree\", \"Feature Selection\": \"None\", \"MSE\": mse_dt, \"MAE\": mae_dt, \"RMSE\": rmse_dt, \"R²\": r2_dt})\n",
    "model_dict[\"DecisionTree_None\"] = dt_pipeline\n",
    "confidence_scores[\"DecisionTree_None\"] = get_confidence_scores(dt_pipeline.named_steps['model'], preprocessor.transform(X_test), \"DecisionTree\")\n",
    "joblib.dump(dt_pipeline, 'models/DecisionTree_None.joblib')\n",
    "pd.DataFrame({'confidence': confidence_scores[\"DecisionTree_None\"]}).to_csv('models/DecisionTree_None_confidence.csv', index=False)\n",
    "\n",
    "# Random Forest\n",
    "rf_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "y_pred_rf = rf_pipeline.predict(X_test)\n",
    "mse_rf, mae_rf, rmse_rf, r2_rf = evaluate_model(y_test, y_pred_rf, \"Random Forest\")\n",
    "results.append({\"Model\": \"Random Forest\", \"Feature Selection\": \"None\", \"MSE\": mse_rf, \"MAE\": mae_rf, \"RMSE\": rmse_rf, \"R²\": r2_rf})\n",
    "model_dict[\"RandomForest_None\"] = rf_pipeline\n",
    "confidence_scores[\"RandomForest_None\"] = get_confidence_scores(rf_pipeline.named_steps['model'], preprocessor.transform(X_test), \"RandomForest\")\n",
    "joblib.dump(rf_pipeline, 'models/RandomForest_None.joblib')\n",
    "pd.DataFrame({'confidence': confidence_scores[\"RandomForest_None\"]}).to_csv('models/RandomForest_None_confidence.csv', index=False)\n",
    "\n",
    "# XGBoost\n",
    "xgb_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', XGBRegressor(random_state=42, objective='reg:squarederror'))\n",
    "])\n",
    "xgb_pipeline.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_pipeline.predict(X_test)\n",
    "mse_xgb, mae_xgb, rmse_xgb, r2_xgb = evaluate_model(y_test, y_pred_xgb, \"XGBoost\")\n",
    "results.append({\"Model\": \"XGBoost\", \"Feature Selection\": \"None\", \"MSE\": mse_xgb, \"MAE\": mae_xgb, \"RMSE\": rmse_xgb, \"R²\": r2_xgb})\n",
    "model_dict[\"XGBoost_None\"] = xgb_pipeline\n",
    "confidence_scores[\"XGBoost_None\"] = get_confidence_scores(xgb_pipeline.named_steps['model'], preprocessor.transform(X_test), \"XGBoost\")\n",
    "joblib.dump(xgb_pipeline, 'models/XGBoost_None.joblib')\n",
    "pd.DataFrame({'confidence': confidence_scores[\"XGBoost_None\"]}).to_csv('models/XGBoost_None_confidence.csv', index=False)\n",
    "\n",
    "# 5. Feature Selection: Mutual Information\n",
    "print(\"\\n=== Feature Selection: Mutual Information ===\")\n",
    "# Buat pipeline dengan feature selection\n",
    "mi_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', SelectKBest(score_func=mutual_info_regression, k=5))\n",
    "])\n",
    "\n",
    "# Fit pipeline untuk mendapatkan fitur terpilih\n",
    "mi_pipeline.fit(X_train, y_train)\n",
    "selected_features_idx = mi_pipeline.named_steps['selector'].get_support()\n",
    "# Dapatkan nama fitur setelah preprocessing\n",
    "feature_names = (mi_pipeline.named_steps['preprocessor']\n",
    "                 .named_transformers_['cat']\n",
    "                 .get_feature_names_out(categorical_columns)\n",
    "                 .tolist() + numeric_columns)\n",
    "selected_features_mi = [feature_names[i] for i, selected in enumerate(selected_features_idx) if selected]\n",
    "print(\"Selected features (MI):\", selected_features_mi)\n",
    "joblib.dump(mi_pipeline.named_steps['selector'], 'models/selector_mi.joblib')\n",
    "joblib.dump(selected_features_mi, 'models/selected_features_mi.joblib')\n",
    "\n",
    "# Decision Tree (MI)\n",
    "dt_mi_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', SelectKBest(score_func=mutual_info_regression, k=5)),\n",
    "    ('model', DecisionTreeRegressor(random_state=42))\n",
    "])\n",
    "dt_mi_pipeline.fit(X_train, y_train)\n",
    "y_pred_dt_mi = dt_mi_pipeline.predict(X_test)\n",
    "mse_dt_mi, mae_dt_mi, rmse_dt_mi, r2_dt_mi = evaluate_model(y_test, y_pred_dt_mi, \"Decision Tree (MI)\")\n",
    "results.append({\"Model\": \"Decision Tree\", \"Feature Selection\": \"MI\", \"MSE\": mse_dt_mi, \"MAE\": mae_dt_mi, \"RMSE\": rmse_dt_mi, \"R²\": r2_dt_mi})\n",
    "model_dict[\"DecisionTree_MI\"] = dt_mi_pipeline\n",
    "confidence_scores[\"DecisionTree_MI\"] = get_confidence_scores(dt_mi_pipeline.named_steps['model'], \n",
    "                                                            dt_mi_pipeline.named_steps['selector'].transform(preprocessor.transform(X_test)), \n",
    "                                                            \"DecisionTree\")\n",
    "joblib.dump(dt_mi_pipeline, 'models/DecisionTree_MI.joblib')\n",
    "pd.DataFrame({'confidence': confidence_scores[\"DecisionTree_MI\"]}).to_csv('models/DecisionTree_MI_confidence.csv', index=False)\n",
    "\n",
    "# Random Forest (MI)\n",
    "rf_mi_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', SelectKBest(score_func=mutual_info_regression, k=5)),\n",
    "    ('model', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "rf_mi_pipeline.fit(X_train, y_train)\n",
    "y_pred_rf_mi = rf_mi_pipeline.predict(X_test)\n",
    "mse_rf_mi, mae_rf_mi, rmse_rf_mi, r2_rf_mi = evaluate_model(y_test, y_pred_rf_mi, \"Random Forest (MI)\")\n",
    "results.append({\"Model\": \"Random Forest\", \"Feature Selection\": \"MI\", \"MSE\": mse_rf_mi, \"MAE\": mae_rf_mi, \"RMSE\": rmse_rf_mi, \"R²\": r2_rf_mi})\n",
    "model_dict[\"RandomForest_MI\"] = rf_mi_pipeline\n",
    "confidence_scores[\"RandomForest_MI\"] = get_confidence_scores(rf_mi_pipeline.named_steps['model'], \n",
    "                                                            rf_mi_pipeline.named_steps['selector'].transform(preprocessor.transform(X_test)), \n",
    "                                                            \"RandomForest\")\n",
    "joblib.dump(rf_mi_pipeline, 'models/RandomForest_MI.joblib')\n",
    "pd.DataFrame({'confidence': confidence_scores[\"RandomForest_MI\"]}).to_csv('models/RandomForest_MI_confidence.csv', index=False)\n",
    "\n",
    "# XGBoost (MI)\n",
    "xgb_mi_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', SelectKBest(score_func=mutual_info_regression, k=5)),\n",
    "    ('model', XGBRegressor(random_state=42, objective='reg:squarederror'))\n",
    "])\n",
    "xgb_mi_pipeline.fit(X_train, y_train)\n",
    "y_pred_xgb_mi = xgb_mi_pipeline.predict(X_test)\n",
    "mse_xgb_mi, mae_xgb_mi, rmse_xgb_mi, r2_xgb_mi = evaluate_model(y_test, y_pred_xgb_mi, \"XGBoost (MI)\")\n",
    "results.append({\"Model\": \"XGBoost\", \"Feature Selection\": \"MI\", \"MSE\": mse_xgb_mi, \"MAE\": mae_xgb_mi, \"RMSE\": rmse_xgb_mi, \"R²\": r2_xgb_mi})\n",
    "model_dict[\"XGBoost_MI\"] = xgb_mi_pipeline\n",
    "confidence_scores[\"XGBoost_MI\"] = get_confidence_scores(xgb_mi_pipeline.named_steps['model'], \n",
    "                                                        xgb_mi_pipeline.named_steps['selector'].transform(preprocessor.transform(X_test)), \n",
    "                                                        \"XGBoost\")\n",
    "joblib.dump(xgb_mi_pipeline, 'models/XGBoost_MI.joblib')\n",
    "pd.DataFrame({'confidence': confidence_scores[\"XGBoost_MI\"]}).to_csv('models/XGBoost_MI_confidence.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "446a0ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Fungsi untuk evaluasi model\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"\\n{model_name} - Metrics\")\n",
    "    print(f\"MSE: {mse:.2f}\")\n",
    "    print(f\"MAE: {mae:.2f}\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(f\"R² Score: {r2:.4f}\")\n",
    "    return mse, mae, rmse, r2\n",
    "\n",
    "# Fungsi untuk menghitung confidence scores\n",
    "def get_confidence_scores(model, X_test, model_type):\n",
    "    if model_type == \"DecisionTree\":\n",
    "        n_bootstraps = 100\n",
    "        predictions = []\n",
    "        for _ in range(n_bootstraps):\n",
    "            idx = np.random.choice(X_test.shape[0], size=X_test.shape[0], replace=True)\n",
    "            X_boot = X_test[idx]\n",
    "            predictions.append(model.predict(X_boot))\n",
    "        predictions = np.array(predictions)\n",
    "        mean_pred = predictions.mean(axis=0)\n",
    "        std_pred = predictions.std(axis=0)\n",
    "        confidence_scores = 1 / (1 + std_pred / (mean_pred + 1e-10))\n",
    "    elif model_type == \"RandomForest\":\n",
    "        tree_predictions = np.array([tree.predict(X_test) for tree in model.estimators_])\n",
    "        mean_pred = tree_predictions.mean(axis=0)\n",
    "        std_pred = tree_predictions.std(axis=0)\n",
    "        confidence_scores = 1 / (1 + std_pred / (mean_pred + 1e-10))\n",
    "    elif model_type == \"XGBoost\":\n",
    "        n_samples = 100\n",
    "        predictions = []\n",
    "        for _ in range(n_samples):\n",
    "            noise = np.random.normal(0, 0.01, X_test.shape)\n",
    "            X_noisy = X_test + noise\n",
    "            predictions.append(model.predict(X_noisy))\n",
    "        predictions = np.array(predictions)\n",
    "        mean_pred = predictions.mean(axis=0)\n",
    "        std_pred = predictions.std(axis=0)\n",
    "        confidence_scores = 1 / (1 + std_pred / (mean_pred + 1e-10))\n",
    "    return confidence_scores\n",
    "\n",
    "# Buat folder models jika belum ada\n",
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models')\n",
    "\n",
    "# 1. Muat dataset\n",
    "data = pd.read_csv('Flight Price Prediction Dataset.csv')\n",
    "\n",
    "# 2. Preprocessing\n",
    "if 'Unnamed: 0' in data.columns:\n",
    "    data = data.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "if data.isnull().sum().sum() > 0:\n",
    "    print(\"Data memiliki nilai null, mengisi dengan modus untuk kategorikal dan rata-rata untuk numerik...\")\n",
    "    for col in data.columns:\n",
    "        if data[col].dtype == 'object':\n",
    "            data[col] = data[col].fillna(data[col].mode()[0])\n",
    "        else:\n",
    "            data[col] = data[col].fillna(data[col].mean())\n",
    "\n",
    "X = data.drop(columns=['price'])\n",
    "y = data['price']\n",
    "\n",
    "# Simpan nilai unik untuk dropdown dashboard\n",
    "unique_values = {}\n",
    "categorical_columns = ['airline', 'flight', 'source_city', 'departure_time', 'stops', \n",
    "                      'arrival_time', 'destination_city', 'class']\n",
    "for col in categorical_columns:\n",
    "    unique_values[col] = list(X[col].unique())\n",
    "joblib.dump(unique_values, 'models/unique_values.joblib')\n",
    "\n",
    "airline_flight_map = X.groupby('airline')['flight'].unique().to_dict()\n",
    "joblib.dump(airline_flight_map, 'models/airline_flight_map.joblib')\n",
    "\n",
    "numeric_columns = ['duration', 'days_left']\n",
    "\n",
    "# Buat preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_columns),\n",
    "        ('num', StandardScaler(), numeric_columns)\n",
    "    ])\n",
    "\n",
    "joblib.dump(preprocessor, 'models/preprocessor.joblib')\n",
    "\n",
    "# Pisahkan data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "joblib.dump((X_train, X_test, y_train, y_test), 'models/processed_data.joblib')\n",
    "\n",
    "# Simpan scaler untuk numerik\n",
    "# Simpan scaler untuk numerik\n",
    "preprocessor.fit(X_train)\n",
    "scaler = preprocessor.named_transformers_['num']  # Corrected line\n",
    "joblib.dump(scaler, 'models/scaler.joblib')\n",
    "\n",
    "\n",
    "# 3. Inisialisasi hasil dan model\n",
    "results = []\n",
    "model_dict = {}\n",
    "confidence_scores = {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af828a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Non-Feature Selection ===\n",
      "\n",
      "Decision Tree - Metrics\n",
      "MSE: 8865106.64\n",
      "MAE: 878.96\n",
      "RMSE: 2977.43\n",
      "R² Score: 0.9828\n"
     ]
    }
   ],
   "source": [
    "# 4. Pelatihan model tanpa feature selection\n",
    "print(\"\\n=== Non-Feature Selection ===\")\n",
    "\n",
    "# Decision Tree\n",
    "dt_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', DecisionTreeRegressor(random_state=42))\n",
    "])\n",
    "dt_pipeline.fit(X_train, y_train)\n",
    "y_pred_dt = dt_pipeline.predict(X_test)\n",
    "mse_dt, mae_dt, rmse_dt, r2_dt = evaluate_model(y_test, y_pred_dt, \"Decision Tree\")\n",
    "results.append({\"Model\": \"Decision Tree\", \"Feature Selection\": \"None\", \"MSE\": mse_dt, \"MAE\": mae_dt, \"RMSE\": rmse_dt, \"R²\": r2_dt})\n",
    "model_dict[\"DecisionTree_None\"] = dt_pipeline\n",
    "confidence_scores[\"DecisionTree_None\"] = get_confidence_scores(dt_pipeline.named_steps['model'], preprocessor.transform(X_test), \"DecisionTree\")\n",
    "joblib.dump(dt_pipeline, 'models/DecisionTree_None.joblib')\n",
    "pd.DataFrame({'confidence': confidence_scores[\"DecisionTree_None\"]}).to_csv('models/DecisionTree_None_confidence.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "964f85aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest - Metrics\n",
      "MSE: 5646696.32\n",
      "MAE: 857.93\n",
      "RMSE: 2376.28\n",
      "R² Score: 0.9890\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "y_pred_rf = rf_pipeline.predict(X_test)\n",
    "mse_rf, mae_rf, rmse_rf, r2_rf = evaluate_model(y_test, y_pred_rf, \"Random Forest\")\n",
    "results.append({\"Model\": \"Random Forest\", \"Feature Selection\": \"None\", \"MSE\": mse_rf, \"MAE\": mae_rf, \"RMSE\": rmse_rf, \"R²\": r2_rf})\n",
    "model_dict[\"RandomForest_None\"] = rf_pipeline\n",
    "confidence_scores[\"RandomForest_None\"] = get_confidence_scores(rf_pipeline.named_steps['model'], preprocessor.transform(X_test), \"RandomForest\")\n",
    "joblib.dump(rf_pipeline, 'models/RandomForest_None.joblib')\n",
    "pd.DataFrame({'confidence': confidence_scores[\"RandomForest_None\"]}).to_csv('models/RandomForest_None_confidence.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0d207f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost - Metrics\n",
      "MSE: 11730853.49\n",
      "MAE: 1962.96\n",
      "RMSE: 3425.03\n",
      "R² Score: 0.9772\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "xgb_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', XGBRegressor(random_state=42, objective='reg:squarederror'))\n",
    "])\n",
    "xgb_pipeline.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_pipeline.predict(X_test)\n",
    "mse_xgb, mae_xgb, rmse_xgb, r2_xgb = evaluate_model(y_test, y_pred_xgb, \"XGBoost\")\n",
    "results.append({\"Model\": \"XGBoost\", \"Feature Selection\": \"None\", \"MSE\": mse_xgb, \"MAE\": mae_xgb, \"RMSE\": rmse_xgb, \"R²\": r2_xgb})\n",
    "model_dict[\"XGBoost_None\"] = xgb_pipeline\n",
    "confidence_scores[\"XGBoost_None\"] = get_confidence_scores(xgb_pipeline.named_steps['model'], preprocessor.transform(X_test), \"XGBoost\")\n",
    "joblib.dump(xgb_pipeline, 'models/XGBoost_None.joblib')\n",
    "pd.DataFrame({'confidence': confidence_scores[\"XGBoost_None\"]}).to_csv('models/XGBoost_None_confidence.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da098331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Feature Selection: Mutual Information ===\n",
      "Selected features (MI): ['airline_Vistara', 'class_Business', 'class_Economy', 'duration', 'days_left']\n",
      "\n",
      "Decision Tree (MI) - Metrics\n",
      "MSE: 38372030.86\n",
      "MAE: 3591.68\n",
      "RMSE: 6194.52\n",
      "R² Score: 0.9256\n"
     ]
    }
   ],
   "source": [
    "# 5. Feature Selection: Mutual Information\n",
    "print(\"\\n=== Feature Selection: Mutual Information ===\")\n",
    "# Buat pipeline dengan feature selection\n",
    "mi_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', SelectKBest(score_func=mutual_info_regression, k=5))\n",
    "])\n",
    "\n",
    "# Fit pipeline untuk mendapatkan fitur terpilih\n",
    "mi_pipeline.fit(X_train, y_train)\n",
    "selected_features_idx = mi_pipeline.named_steps['selector'].get_support()\n",
    "# Dapatkan nama fitur setelah preprocessing\n",
    "feature_names = (mi_pipeline.named_steps['preprocessor']\n",
    "                 .named_transformers_['cat']\n",
    "                 .get_feature_names_out(categorical_columns)\n",
    "                 .tolist() + numeric_columns)\n",
    "selected_features_mi = [feature_names[i] for i, selected in enumerate(selected_features_idx) if selected]\n",
    "print(\"Selected features (MI):\", selected_features_mi)\n",
    "joblib.dump(mi_pipeline.named_steps['selector'], 'models/selector_mi.joblib')\n",
    "joblib.dump(selected_features_mi, 'models/selected_features_mi.joblib')\n",
    "\n",
    "# Decision Tree (MI)\n",
    "dt_mi_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', SelectKBest(score_func=mutual_info_regression, k=5)),\n",
    "    ('model', DecisionTreeRegressor(random_state=42))\n",
    "])\n",
    "dt_mi_pipeline.fit(X_train, y_train)\n",
    "y_pred_dt_mi = dt_mi_pipeline.predict(X_test)\n",
    "mse_dt_mi, mae_dt_mi, rmse_dt_mi, r2_dt_mi = evaluate_model(y_test, y_pred_dt_mi, \"Decision Tree (MI)\")\n",
    "results.append({\"Model\": \"Decision Tree\", \"Feature Selection\": \"MI\", \"MSE\": mse_dt_mi, \"MAE\": mae_dt_mi, \"RMSE\": rmse_dt_mi, \"R²\": r2_dt_mi})\n",
    "model_dict[\"DecisionTree_MI\"] = dt_mi_pipeline\n",
    "confidence_scores[\"DecisionTree_MI\"] = get_confidence_scores(dt_mi_pipeline.named_steps['model'], \n",
    "                                                            dt_mi_pipeline.named_steps['selector'].transform(preprocessor.transform(X_test)), \n",
    "                                                            \"DecisionTree\")\n",
    "joblib.dump(dt_mi_pipeline, 'models/DecisionTree_MI.joblib')\n",
    "pd.DataFrame({'confidence': confidence_scores[\"DecisionTree_MI\"]}).to_csv('models/DecisionTree_MI_confidence.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afe9957c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest (MI) - Metrics\n",
      "MSE: 34637319.52\n",
      "MAE: 3455.38\n",
      "RMSE: 5885.35\n",
      "R² Score: 0.9328\n"
     ]
    }
   ],
   "source": [
    "# Random Forest (MI)\n",
    "rf_mi_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', SelectKBest(score_func=mutual_info_regression, k=5)),\n",
    "    ('model', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "rf_mi_pipeline.fit(X_train, y_train)\n",
    "y_pred_rf_mi = rf_mi_pipeline.predict(X_test)\n",
    "mse_rf_mi, mae_rf_mi, rmse_rf_mi, r2_rf_mi = evaluate_model(y_test, y_pred_rf_mi, \"Random Forest (MI)\")\n",
    "results.append({\"Model\": \"Random Forest\", \"Feature Selection\": \"MI\", \"MSE\": mse_rf_mi, \"MAE\": mae_rf_mi, \"RMSE\": rmse_rf_mi, \"R²\": r2_rf_mi})\n",
    "model_dict[\"RandomForest_MI\"] = rf_mi_pipeline\n",
    "confidence_scores[\"RandomForest_MI\"] = get_confidence_scores(rf_mi_pipeline.named_steps['model'], \n",
    "                                                            rf_mi_pipeline.named_steps['selector'].transform(preprocessor.transform(X_test)), \n",
    "                                                            \"RandomForest\")\n",
    "joblib.dump(rf_mi_pipeline, 'models/RandomForest_MI.joblib')\n",
    "pd.DataFrame({'confidence': confidence_scores[\"RandomForest_MI\"]}).to_csv('models/RandomForest_MI_confidence.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2057cd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost (MI) - Metrics\n",
      "MSE: 26524799.25\n",
      "MAE: 3051.95\n",
      "RMSE: 5150.22\n",
      "R² Score: 0.9485\n"
     ]
    }
   ],
   "source": [
    "# XGBoost (MI)\n",
    "xgb_mi_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', SelectKBest(score_func=mutual_info_regression, k=5)),\n",
    "    ('model', XGBRegressor(random_state=42, objective='reg:squarederror'))\n",
    "])\n",
    "xgb_mi_pipeline.fit(X_train, y_train)\n",
    "y_pred_xgb_mi = xgb_mi_pipeline.predict(X_test)\n",
    "mse_xgb_mi, mae_xgb_mi, rmse_xgb_mi, r2_xgb_mi = evaluate_model(y_test, y_pred_xgb_mi, \"XGBoost (MI)\")\n",
    "results.append({\"Model\": \"XGBoost\", \"Feature Selection\": \"MI\", \"MSE\": mse_xgb_mi, \"MAE\": mae_xgb_mi, \"RMSE\": rmse_xgb_mi, \"R²\": r2_xgb_mi})\n",
    "model_dict[\"XGBoost_MI\"] = xgb_mi_pipeline\n",
    "confidence_scores[\"XGBoost_MI\"] = get_confidence_scores(xgb_mi_pipeline.named_steps['model'], \n",
    "                                                        xgb_mi_pipeline.named_steps['selector'].transform(preprocessor.transform(X_test)), \n",
    "                                                        \"XGBoost\")\n",
    "joblib.dump(xgb_mi_pipeline, 'models/XGBoost_MI.joblib')\n",
    "pd.DataFrame({'confidence': confidence_scores[\"XGBoost_MI\"]}).to_csv('models/XGBoost_MI_confidence.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f235faeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Feature Selection: SFS ===\n",
      "Selected features (SFS): ['airline_Vistara', 'source_city_Mumbai', 'arrival_time_Night', 'class_Business', 'duration']\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: 'models/sfs.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m selected_features_sfs \u001b[38;5;241m=\u001b[39m [feature_names[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m selected_features_idx]\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSelected features (SFS):\u001b[39m\u001b[38;5;124m\"\u001b[39m, selected_features_sfs)\n\u001b[1;32m---> 16\u001b[0m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43msfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodels/sfs.joblib\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(selected_features_sfs, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/selected_features_sfs.joblib\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\numpy_pickle.py:552\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(value, filename, compress, protocol, cache_size)\u001b[0m\n\u001b[0;32m    550\u001b[0m         NumpyPickler(f, protocol\u001b[38;5;241m=\u001b[39mprotocol)\u001b[38;5;241m.\u001b[39mdump(value)\n\u001b[0;32m    551\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_filename:\n\u001b[1;32m--> 552\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    553\u001b[0m         NumpyPickler(f, protocol\u001b[38;5;241m=\u001b[39mprotocol)\u001b[38;5;241m.\u001b[39mdump(value)\n\u001b[0;32m    554\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: 'models/sfs.joblib'"
     ]
    }
   ],
   "source": [
    "# 6. Feature Selection: Sequential Forward Selection (SFS)\n",
    "print(\"\\n=== Feature Selection: SFS ===\")\n",
    "# SFS tidak bisa langsung digunakan dalam pipeline karena membutuhkan data yang sudah di-preprocess\n",
    "# Preprocess data terlebih dahulu\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n",
    "feature_names = (preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_columns).tolist() + numeric_columns)\n",
    "\n",
    "# Jalankan SFS\n",
    "sfs = SFS(RandomForestRegressor(n_estimators=10, random_state=42), \n",
    "          k_features=5, forward=True, scoring='r2', cv=5, n_jobs=-1)\n",
    "sfs.fit(X_train_preprocessed, y_train)\n",
    "selected_features_idx = list(sfs.k_feature_idx_)\n",
    "selected_features_sfs = [feature_names[i] for i in selected_features_idx]\n",
    "print(\"Selected features (SFS):\", selected_features_sfs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95f6dd35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:/Data Mining2/models/selected_features_sfs.joblib']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Simpan SFS ke path penuh\n",
    "joblib.dump(sfs, 'D:/Data Mining2/models/sfs.joblib')\n",
    "\n",
    "# Simpan nama fitur terpilih ke path penuh\n",
    "joblib.dump(selected_features_sfs, 'D:/Data Mining2/models/selected_features_sfs.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4f83a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree (SFS) - Metrics\n",
      "MSE: 25191417.40\n",
      "MAE: 3257.76\n",
      "RMSE: 5019.11\n",
      "R² Score: 0.9511\n"
     ]
    }
   ],
   "source": [
    "# Buat pipeline dengan SFS (menggunakan selector manual)\n",
    "class SFSSelector:\n",
    "    def __init__(self, selected_indices):\n",
    "        self.selected_indices = selected_indices\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[:, self.selected_indices]\n",
    "\n",
    "# Decision Tree (SFS)\n",
    "dt_sfs_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', SFSSelector(selected_features_idx)),\n",
    "    ('model', DecisionTreeRegressor(random_state=42))\n",
    "])\n",
    "dt_sfs_pipeline.fit(X_train, y_train)\n",
    "y_pred_dt_sfs = dt_sfs_pipeline.predict(X_test)\n",
    "mse_dt_sfs, mae_dt_sfs, rmse_dt_sfs, r2_dt_sfs = evaluate_model(y_test, y_pred_dt_sfs, \"Decision Tree (SFS)\")\n",
    "results.append({\"Model\": \"Decision Tree\", \"Feature Selection\": \"SFS\", \"MSE\": mse_dt_sfs, \"MAE\": mae_dt_sfs, \"RMSE\": rmse_dt_sfs, \"R²\": r2_dt_sfs})\n",
    "model_dict[\"DecisionTree_SFS\"] = dt_sfs_pipeline\n",
    "confidence_scores[\"DecisionTree_SFS\"] = get_confidence_scores(dt_sfs_pipeline.named_steps['model'], \n",
    "                                                             dt_sfs_pipeline.named_steps['selector'].transform(preprocessor.transform(X_test)), \n",
    "                                                             \"DecisionTree\")\n",
    "joblib.dump(dt_sfs_pipeline, 'D:/Data Mining2/models/DecisionTree_SFS.joblib')\n",
    "pd.DataFrame({'confidence': confidence_scores[\"DecisionTree_SFS\"]}).to_csv('D:/Data Mining2/models/DecisionTree_SFS_confidence.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d8280cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest (SFS) - Metrics\n",
      "MSE: 25182625.91\n",
      "MAE: 3259.33\n",
      "RMSE: 5018.23\n",
      "R² Score: 0.9511\n"
     ]
    }
   ],
   "source": [
    "# Random Forest (SFS)\n",
    "rf_sfs_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', SFSSelector(selected_features_idx)),\n",
    "    ('model', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "rf_sfs_pipeline.fit(X_train, y_train)\n",
    "y_pred_rf_sfs = rf_sfs_pipeline.predict(X_test)\n",
    "mse_rf_sfs, mae_rf_sfs, rmse_rf_sfs, r2_rf_sfs = evaluate_model(y_test, y_pred_rf_sfs, \"Random Forest (SFS)\")\n",
    "results.append({\"Model\": \"Random Forest\", \"Feature Selection\": \"SFS\", \"MSE\": mse_rf_sfs, \"MAE\": mae_rf_sfs, \"RMSE\": rmse_rf_sfs, \"R²\": r2_rf_sfs})\n",
    "model_dict[\"RandomForest_SFS\"] = rf_sfs_pipeline\n",
    "confidence_scores[\"RandomForest_SFS\"] = get_confidence_scores(rf_sfs_pipeline.named_steps['model'], \n",
    "                                                             rf_sfs_pipeline.named_steps['selector'].transform(preprocessor.transform(X_test)), \n",
    "                                                             \"RandomForest\")\n",
    "joblib.dump(rf_sfs_pipeline, 'D:/Data Mining2/models/RandomForest_SFS.joblib')\n",
    "pd.DataFrame({'confidence': confidence_scores[\"RandomForest_SFS\"]}).to_csv('D:/Data Mining2/models/RandomForest_SFS_confidence.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a7df4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost (SFS) - Metrics\n",
      "MSE: 28421890.78\n",
      "MAE: 3504.75\n",
      "RMSE: 5331.22\n",
      "R² Score: 0.9449\n"
     ]
    }
   ],
   "source": [
    "# XGBoost (SFS)\n",
    "xgb_sfs_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', SFSSelector(selected_features_idx)),\n",
    "    ('model', XGBRegressor(random_state=42, objective='reg:squarederror'))\n",
    "])\n",
    "xgb_sfs_pipeline.fit(X_train, y_train)\n",
    "y_pred_xgb_sfs = xgb_sfs_pipeline.predict(X_test)\n",
    "mse_xgb_sfs, mae_xgb_sfs, rmse_xgb_sfs, r2_xgb_sfs = evaluate_model(y_test, y_pred_xgb_sfs, \"XGBoost (SFS)\")\n",
    "results.append({\"Model\": \"XGBoost\", \"Feature Selection\": \"SFS\", \"MSE\": mse_xgb_sfs, \"MAE\": mae_xgb_sfs, \"RMSE\": rmse_xgb_sfs, \"R²\": r2_xgb_sfs})\n",
    "model_dict[\"XGBoost_SFS\"] = xgb_sfs_pipeline\n",
    "confidence_scores[\"XGBoost_SFS\"] = get_confidence_scores(xgb_sfs_pipeline.named_steps['model'], \n",
    "                                                        xgb_sfs_pipeline.named_steps['selector'].transform(preprocessor.transform(X_test)), \n",
    "                                                        \"XGBoost\")\n",
    "joblib.dump(xgb_sfs_pipeline, 'D:/Data Mining2/models/XGBoost_SFS.joblib')\n",
    "pd.DataFrame({'confidence': confidence_scores[\"XGBoost_SFS\"]}).to_csv('D:/Data Mining2/models/XGBoost_SFS_confidence.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2816d914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hasil evaluasi disimpan ke 'models/model_results.csv'\n",
      "\n",
      "=== Comparison Table ===\n",
      "\n",
      "Non-Feature Selection:\n",
      "           Model           MSE          MAE         RMSE        R²\n",
      "0  Decision Tree  8.865107e+06   878.958971  2977.432894  0.982802\n",
      "1  Random Forest  5.646696e+06   857.926063  2376.277828  0.989046\n",
      "2        XGBoost  1.173085e+07  1962.960779  3425.033357  0.977243\n",
      "\n",
      "Mutual Information:\n",
      "           Model           MSE          MAE         RMSE        R²\n",
      "3  Decision Tree  3.837203e+07  3591.682250  6194.516192  0.925561\n",
      "4  Random Forest  3.463732e+07  3455.383906  5885.347867  0.932806\n",
      "5        XGBoost  2.652480e+07  3051.949122  5150.223223  0.948544\n",
      "\n",
      "SFS:\n",
      "            Model           MSE          MAE         RMSE        R²\n",
      "6   Decision Tree  2.519142e+07  3257.760353  5019.105239  0.951130\n",
      "7   Decision Tree  2.519142e+07  3257.760353  5019.105239  0.951130\n",
      "8   Decision Tree  2.519142e+07  3257.760353  5019.105239  0.951130\n",
      "9   Decision Tree  2.519142e+07  3257.760353  5019.105239  0.951130\n",
      "10  Random Forest  2.518263e+07  3259.334808  5018.229360  0.951147\n",
      "11        XGBoost  2.842189e+07  3504.747344  5331.218508  0.944863\n",
      "Confidence scores disimpan ke 'models/confidence_scores.joblib'\n"
     ]
    }
   ],
   "source": [
    "# 7. Simpan hasil evaluasi\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('D:/Data Mining2/models/model_results.csv', index=False)\n",
    "print(\"\\nHasil evaluasi disimpan ke 'models/model_results.csv'\")\n",
    "\n",
    "# Cetak perbandingan\n",
    "print(\"\\n=== Comparison Table ===\")\n",
    "print(\"\\nNon-Feature Selection:\")\n",
    "print(results_df[results_df['Feature Selection'] == 'None'][['Model', 'MSE', 'MAE', 'RMSE', 'R²']])\n",
    "print(\"\\nMutual Information:\")\n",
    "print(results_df[results_df['Feature Selection'] == 'MI'][['Model', 'MSE', 'MAE', 'RMSE', 'R²']])\n",
    "print(\"\\nSFS:\")\n",
    "print(results_df[results_df['Feature Selection'] == 'SFS'][['Model', 'MSE', 'MAE', 'RMSE', 'R²']])\n",
    "\n",
    "# Simpan confidence scores\n",
    "joblib.dump(confidence_scores, 'D:/Data Mining2/models/confidence_scores.joblib')\n",
    "print(\"Confidence scores disimpan ke 'models/confidence_scores.joblib'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f397ebe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:/Data Mining2/models/selector_sfs.joblib']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(SFSSelector(selected_features_idx), 'D:/Data Mining2/models/selector_sfs.joblib')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
